{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61933db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0+cu102\n",
      "torchvision version: 0.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5748506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"/home/pocmst/Development/datasets/torch\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"/home/pocmst/Development/datasets/torch\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2804f508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See first training sample\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1993511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39b3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f2f8eab8588>, <torch.utils.data.dataloader.DataLoader object at 0x7f307366f7f0>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "863d8921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35cd3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 1, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(train_data.classes[label])\n",
    "plt.axis(\"Off\");\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c9e8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "Shape after flattening: torch.Size([1, 784]) -> [colors_channel, height * width]\n"
     ]
    }
   ],
   "source": [
    "flatten_model = nn.Flatten()\n",
    "\n",
    "x = train_features_batch[0]\n",
    "\n",
    "output = flatten_model(x)\n",
    "\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [colors_channel, height * width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb17af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTV1(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # 784 inputnya\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4563cefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = FashionMNISTV1(input_shape=784, hidden_units=10, output_shape=len(train_data.classes))\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e222891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)\n",
    "    \n",
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f3f4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ba84bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start, end, device=None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5235e5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24886aec2d7743e7b645bddbb9475021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.59484 | Test loss: 0.51635, Test acc: 81.84%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.47946 | Test loss: 0.48138, Test acc: 83.18%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.45703 | Test loss: 0.47773, Test acc: 83.50%\n",
      "\n",
      "Train time on cpu: 20.103 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "        \n",
    "        # 2. Calculate loss (per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "    \n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X)\n",
    "            \n",
    "            # 2. Calculate loss (accumatively)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            \n",
    "            # 3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "        \n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37db31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b17c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ebd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
