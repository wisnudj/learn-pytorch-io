{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7133e-00d9-4204-9b33-9d201debab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from going_modular import data_setup, engine\n",
    "\n",
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.engine import train_step, test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c561b7-ebcd-4d45-86b9-5c235a0f4b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ff81d9-4935-4a80-987f-2971fc7d5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "def download_data(source : str, destination : str, remove_source : bool = True):\n",
    "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
    "\n",
    "    Args:\n",
    "        source (str): A link to a zipped file containing data.\n",
    "        destination (str): A target directory to unzip data to.\n",
    "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
    "    \n",
    "    Returns:\n",
    "        pathlib.Path to downloaded data.\n",
    "    \n",
    "    Example usage:\n",
    "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                      destination=\"pizza_steak_sushi\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination\n",
    "    \n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)    \n",
    "        \n",
    "        target_file = Path(source).name\n",
    "        \n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.contentent)\n",
    "            \n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
    "            zip_ref.extractall(image_path)\n",
    "            \n",
    "        # remove zipfile\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "            \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a19a95-1485-4f71-a091-dd25cb942341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data/pizza_steak_sushi directory exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                          destination=\"pizza_steak_sushi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d263cc-3214-4306-b77a-2ac184477d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir, test_dir=test_dir, transform=manual_transforms, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587296f4-a4e4-4fac-88cd-2d1b99b26e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
    "\n",
    "# Freeze all base layers by setting requires_grad attribute to False\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Since we're creating a new layer with random weights (torch.nn.Linear), \n",
    "# let's set the seeds\n",
    "set_seeds() \n",
    "\n",
    "# Update the classifier head to suit our problem\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names),bias=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19581411-f877-43e1-ab3d-71949cdfbbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                                      Output Shape         Param #\n",
       "====================================================================================================\n",
       "EfficientNet                                                 --                   --\n",
       "├─Sequential (features)                                      [32, 1280, 7, 7]     --\n",
       "│    └─ConvNormActivation (0)                                [32, 32, 112, 112]   --\n",
       "│    │    └─Conv2d (0)                                       [32, 32, 112, 112]   (864)\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   (64)\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   --\n",
       "│    └─Sequential (1)                                        [32, 16, 112, 112]   --\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   (1,448)\n",
       "│    └─Sequential (2)                                        [32, 24, 56, 56]     --\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     (6,004)\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     (10,710)\n",
       "│    └─Sequential (3)                                        [32, 40, 28, 28]     --\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     (15,350)\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     (31,290)\n",
       "│    └─Sequential (4)                                        [32, 80, 14, 14]     --\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     (37,130)\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     (102,900)\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     (102,900)\n",
       "│    └─Sequential (5)                                        [32, 112, 14, 14]    --\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    (126,004)\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    (208,572)\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    (208,572)\n",
       "│    └─Sequential (6)                                        [32, 192, 7, 7]      --\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      (262,492)\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      (587,952)\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      (587,952)\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      (587,952)\n",
       "│    └─Sequential (7)                                        [32, 320, 7, 7]      --\n",
       "│    │    └─MBConv (0)                                       [32, 320, 7, 7]      (717,232)\n",
       "│    └─ConvNormActivation (8)                                [32, 1280, 7, 7]     --\n",
       "│    │    └─Conv2d (0)                                       [32, 1280, 7, 7]     (409,600)\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     (2,560)\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 1, 1]     --\n",
       "├─Sequential (classifier)                                    [32, 3]              --\n",
       "│    └─Dropout (0)                                           [32, 1280]           --\n",
       "│    └─Linear (1)                                            [32, 3]              3,843\n",
       "====================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "====================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(32, 3, 224, 224), verbose=0, col_width=20, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307ec165-ada7-4cf6-8ea4-98d8c95edc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d126ab-bb32-4d90-b87a-949187e51d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e423ddf-af1b-49ee-ad67-79d513e2682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "# Import train() function from: \n",
    "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "      model: A PyTorch model to be trained and tested.\n",
    "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "      epochs: An integer indicating how many epochs to train for.\n",
    "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      A dictionary of training and testing loss as well as training and\n",
    "      testing accuracy metrics. Each metric has a value in a list for \n",
    "      each epoch.\n",
    "      In the form: {train_loss: [...],\n",
    "                train_acc: [...],\n",
    "                test_loss: [...],\n",
    "                test_acc: [...]} \n",
    "      For example if training for epochs=2: \n",
    "              {train_loss: [2.0616, 1.0537],\n",
    "                train_acc: [0.3945, 0.3945],\n",
    "                test_loss: [1.2641, 1.5706],\n",
    "                test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "#         ### New: Experiment tracking ###\n",
    "#         # Add loss results to SummaryWriter\n",
    "#         writer.add_scalars(main_tag=\"Loss\", \n",
    "#                            tag_scalar_dict={\"train_loss\": train_loss,\n",
    "#                                             \"test_loss\": test_loss},\n",
    "#                            global_step=epoch)\n",
    "\n",
    "#         # Add accuracy results to SummaryWriter\n",
    "#         writer.add_scalars(main_tag=\"Accuracy\", \n",
    "#                            tag_scalar_dict={\"train_acc\": train_acc,\n",
    "#                                             \"test_acc\": test_acc}, \n",
    "#                            global_step=epoch)\n",
    "        \n",
    "#         # Track the PyTorch model architecture\n",
    "#         writer.add_graph(model=model, \n",
    "#                          # Pass in an example input\n",
    "#                          input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "    \n",
    "#     # Close the writer\n",
    "#     writer.close()\n",
    "    \n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0feca62c-e134-4f0f-a84b-64eb7053230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d802712950794b8e9ff15c1ff5b444f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0908 | train_acc: 0.4453 | test_loss: 0.9066 | test_acc: 0.5284\n",
      "Epoch: 2 | train_loss: 0.8667 | train_acc: 0.7773 | test_loss: 0.7938 | test_acc: 0.7538\n",
      "Epoch: 3 | train_loss: 0.7633 | train_acc: 0.7930 | test_loss: 0.7378 | test_acc: 0.7936\n",
      "Epoch: 4 | train_loss: 0.7271 | train_acc: 0.7383 | test_loss: 0.6497 | test_acc: 0.8759\n",
      "Epoch: 5 | train_loss: 0.6380 | train_acc: 0.7852 | test_loss: 0.6222 | test_acc: 0.9072\n",
      "Epoch: 6 | train_loss: 0.5963 | train_acc: 0.7617 | test_loss: 0.5554 | test_acc: 0.9072\n",
      "Epoch: 7 | train_loss: 0.5376 | train_acc: 0.9219 | test_loss: 0.5253 | test_acc: 0.9176\n",
      "Epoch: 8 | train_loss: 0.5546 | train_acc: 0.7930 | test_loss: 0.5231 | test_acc: 0.9176\n",
      "Epoch: 9 | train_loss: 0.5638 | train_acc: 0.8008 | test_loss: 0.4919 | test_acc: 0.9280\n",
      "Epoch: 10 | train_loss: 0.5136 | train_acc: 0.8086 | test_loss: 0.4180 | test_acc: 0.8655\n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "\n",
    "# Setup training and save the results\n",
    "results = train(model=model,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_fn=loss_fn,\n",
    "                       epochs=10,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084701a7-8354-4575-8e60-d7bdcdae7799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f0126d7c8b345963\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f0126d7c8b345963\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example code to run in Jupyter or Google Colab Notebook (uncomment to try it out)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184fa74-7b8d-44e7-a14f-9759ae6fd1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acda7b-ea10-42cd-8748-01574375daf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95eead-f846-49ce-ba4d-3fb7e83a69fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131799ac-a4aa-4bad-8bc9-f5e3f3737362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67f7c5-c604-45a2-b9c2-cce0e40f6ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430d81f-5e56-43ab-8735-d735fa714aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b1387-706d-4922-b4dd-b9695c1646b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
